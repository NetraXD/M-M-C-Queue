{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD7or-AMj3JJ"
      },
      "source": [
        "MAT099_C21091451\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Topic: Queue Simulation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCyx4S6kj-EP"
      },
      "source": [
        "Installing ciw library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo4IOxRYkBJ3",
        "outputId": "9983486b-aff2-4e4d-bb27-9f477ece0939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ciw\n",
            "  Downloading ciw-3.2.5-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: setuptools>=69 in /usr/local/lib/python3.11/dist-packages (from ciw) (75.2.0)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.11/dist-packages (from ciw) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from ciw) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from ciw) (2.0.2)\n",
            "Downloading ciw-3.2.5-py3-none-any.whl (103 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/103.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ciw\n",
            "Successfully installed ciw-3.2.5\n"
          ]
        }
      ],
      "source": [
        "pip install ciw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2ws_zYTjlDT"
      },
      "outputs": [],
      "source": [
        "\"\"\"PART1: SIMULATE THE M/M/C QUEUE\"\"\"\n",
        "#import required libraries\n",
        "import ciw\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#generate different values of lambda, mu, c\n",
        "bArray = np.arange(0.1, 10, 0.2)\n",
        "cArray = np.arange(1, 10, 1)\n",
        "df = pd.DataFrame()\n",
        "df['a'] = []\n",
        "df['b'] = []\n",
        "df['c'] = []\n",
        "df['res'] = []\n",
        "\n",
        "#Simulate the desired value for the pair of (lambda, mu, c)\n",
        "s = 0\n",
        "for b in bArray:\n",
        "    for c in cArray:\n",
        "        bc = b * c\n",
        "        aArray = np.linspace(bc / 20, 19 * bc / 20, 40) ## a / (b * c) < 1\n",
        "        for a in aArray:\n",
        "            N = ciw.create_network(arrival_distributions=[ciw.dists.Exponential(rate=a)],\n",
        "                    service_distributions=[ciw.dists.Exponential(rate=b)],\n",
        "                    number_of_servers=[int(c)])\n",
        "            average_waits = []\n",
        "            for trial in range(10):\n",
        "                ciw.seed(trial)\n",
        "                Q = ciw.Simulation(N)\n",
        "                Q.simulate_until_max_time(1440)\n",
        "                recs = Q.get_all_records()\n",
        "                waits = [r.waiting_time for r in recs]\n",
        "                mean_wait = sum(waits) / len(waits)\n",
        "                average_waits.append(mean_wait)\n",
        "            res = sum(average_waits) / len(average_waits)\n",
        "            df1 = pd.DataFrame()\n",
        "            df1['a'] = [a]\n",
        "            df1['b'] = [b]\n",
        "            df1['c'] = [c]\n",
        "            df1['res'] = [res]\n",
        "            df = pd.concat([df, df1], axis=0)\n",
        "            s += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-RT3UgzvNZi"
      },
      "outputs": [],
      "source": [
        "#Save the generated dataset\n",
        "df.to_csv('FinalDataset.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoivZYunjlDU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e1c75447-df60-46a4-a5ca-92dc1d3ee9b2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-52a4ba5494e4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#Split the dataset into trainng and test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "\"\"\"PART2: TRAINING AND SIMULATION OF LINEAR REGRESSION MODELS\"\"\"\n",
        "\n",
        "#import required libraries\n",
        "import pandas as pd\n",
        "from random import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import linear_model\n",
        "from sklearn import svm\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import sklearn.metrics as sm\n",
        "\n",
        "#import the dataset\n",
        "df = pd.read_csv('FinalDataset.csv')\n",
        "df['abc'] = df['a'] / (df['b'] * df['c'])\n",
        "X = df.iloc[:, [0, 1, 2, 4]].values\n",
        "#X = df.iloc[:, 0:3].values\n",
        "y = df['res'].values\n",
        "\n",
        "#Split the dataset into trainng and test dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=100\n",
        ")\n",
        "\n",
        "#Scale the dataset with the Standard Scaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "reg = linear_model.LinearRegression()\n",
        "\n",
        "#Train the training dataset\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "#Predict the training dataset\n",
        "reg.fit(X_train, y_train)\n",
        "y_test_pred = reg.predict(scaler.transform(X_test))\n",
        "\n",
        "#print the MAE, MSE, R2-SCORE\n",
        "print(\"Mean absolute error = \", round(sm.mean_absolute_error(y_test, y_test_pred), 2))\n",
        "print(\"Mean squared error = \", round(sm.mean_squared_error(y_test, y_test_pred), 2))\n",
        "print(\"R2 score = \", round(sm.r2_score(y_test, y_test_pred), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gX1xknusjlDV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "df621fb7-a569-4893-9bb4-b6fde82877ad"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6c704af62f86>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#Split the dataset into trainng and test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "\"\"\"PART3: TRAINING AND SIMULATION OF SVR MODELS\"\"\"\n",
        "\n",
        "#import required libraries\n",
        "import pandas as pd\n",
        "from random import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import linear_model\n",
        "from sklearn import svm\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import sklearn.metrics as sm\n",
        "\n",
        "#import the dataset\n",
        "df = pd.read_csv('FinalDataset.csv')\n",
        "df['abc'] = df['a'] / (df['b'] * df['c'])\n",
        "X = df.iloc[:, [0, 1, 2, 4]].values\n",
        "#X = df.iloc[:, 0:3].values\n",
        "y = df['res'].values\n",
        "\n",
        "#Split the dataset into trainng and test dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=100\n",
        ")\n",
        "\n",
        "#Scale the dataset with the Standard Scaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "reg = svm.SVR(kernel='rbf', C=50, gamma = 20)\n",
        "\n",
        "#Train the training dataset\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "#Predict the training dataset\n",
        "y_test_pred = reg.predict(scaler.transform(X_test))\n",
        "\n",
        "#Show the MAE, MSE, R2-SCORE\n",
        "print(\"Mean absolute error = \", round(sm.mean_absolute_error(y_test, y_test_pred), 2))\n",
        "print(\"Mean squared error = \", round(sm.mean_squared_error(y_test, y_test_pred), 2))\n",
        "print(\"R2 score = \", round(sm.r2_score(y_test, y_test_pred), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8c3dH6RjlDW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "58256868-eb06-4d7d-81ad-cc8fd9f4f14e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a8aad2678dfb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#Split the dataset into trainng and test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "\"\"\"PART4: TRAINING AND SIMULATION OF XGBOOST REGRESSOR\"\"\"\n",
        "\n",
        "#import required libraries\n",
        "import pandas as pd\n",
        "from random import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import linear_model\n",
        "from sklearn import svm\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import sklearn.metrics as sm\n",
        "\n",
        "#import the dataset\n",
        "df = pd.read_csv('FinalDataset.csv')\n",
        "df['abc'] = df['a'] / (df['b'] * df['c'])\n",
        "X = df.iloc[:, [0, 1, 2, 4]].values\n",
        "#X = df.iloc[:, 0:3].values\n",
        "y = df['res'].values\n",
        "\n",
        "#Split the dataset into trainng and test dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=100\n",
        ")\n",
        "\n",
        "#Scale the dataset with the Standard Scaler\n",
        "scaler = StandardScaler()\n",
        "#scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "reg = xgb.XGBRegressor()\n",
        "\n",
        "#Train the training dataset\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "#Predict the training dataset\n",
        "y_test_pred = reg.predict(scaler.transform(X_test))\n",
        "\n",
        "#Show the MAE, MSE, R2-SCORE\n",
        "print(\"Mean absolute error = \", round(sm.mean_absolute_error(y_test, y_test_pred), 2))\n",
        "print(\"Mean squared error = \", round(sm.mean_squared_error(y_test, y_test_pred), 2))\n",
        "print(\"R2 score = \", round(sm.r2_score(y_test, y_test_pred), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3-oRarQjlDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b3c433-2a8f-4926-d69e-26a809a6068d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute error =  0.04\n",
            "Mean squared error =  0.28\n",
            "R2 score =  0.94\n"
          ]
        }
      ],
      "source": [
        "\"\"\"PART5: TRAINING AND SIMULATION OF RANDOM FOREST REGRESSOR\"\"\"\n",
        "\n",
        "#import required libraries\n",
        "import pandas as pd\n",
        "from random import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import linear_model\n",
        "from sklearn import svm\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import sklearn.metrics as sm\n",
        "\n",
        "#import the dataset\n",
        "df = pd.read_csv('FinalDataset.csv')\n",
        "df['abc'] = df['a'] / (df['b'] * df['c'])\n",
        "X = df.iloc[:, [0, 1, 2, 4]].values\n",
        "#X = df.iloc[:, 0:3].values\n",
        "y = df['res'].values\n",
        "\n",
        "#Split the dataset into trainng and test dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=100\n",
        ")\n",
        "\n",
        "#Scale the dataset with the Standard Scaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "reg = RandomForestRegressor()\n",
        "\n",
        "#Train the training dataset\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "#Predict the training dataset\n",
        "y_test_pred = reg.predict(scaler.transform(X_test))\n",
        "\n",
        "#Show the MAE, MSE, R2-SCORE\n",
        "print(\"Mean absolute error = \", round(sm.mean_absolute_error(y_test, y_test_pred), 2))\n",
        "print(\"Mean squared error = \", round(sm.mean_squared_error(y_test, y_test_pred), 2))\n",
        "print(\"R2 score = \", round(sm.r2_score(y_test, y_test_pred), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSyy8NvzjlDX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79be54f7-dc76-4047-d7e0-b68794b23cd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                50        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 50)                550       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 200)               10200     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 50)                10050     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                510       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,371\n",
            "Trainable params: 21,371\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "781/781 [==============================] - 3s 2ms/step - loss: 1.9617 - mse: 1.9617\n",
            "Epoch 2/15\n",
            "781/781 [==============================] - 2s 2ms/step - loss: 1.0115 - mse: 1.0115\n",
            "Epoch 3/15\n",
            "781/781 [==============================] - 2s 2ms/step - loss: 0.7549 - mse: 0.7549\n",
            "Epoch 4/15\n",
            "781/781 [==============================] - 2s 2ms/step - loss: 0.6170 - mse: 0.6170\n",
            "Epoch 5/15\n",
            "781/781 [==============================] - 2s 2ms/step - loss: 0.5622 - mse: 0.5622\n",
            "Epoch 6/15\n",
            "781/781 [==============================] - 2s 2ms/step - loss: 0.5154 - mse: 0.5154\n",
            "Epoch 7/15\n",
            "781/781 [==============================] - 2s 3ms/step - loss: 0.4806 - mse: 0.4806\n",
            "Epoch 8/15\n",
            "781/781 [==============================] - 2s 2ms/step - loss: 0.4311 - mse: 0.4311\n",
            "Epoch 9/15\n",
            "781/781 [==============================] - 2s 2ms/step - loss: 0.3948 - mse: 0.3948\n",
            "Epoch 10/15\n",
            "781/781 [==============================] - 2s 2ms/step - loss: 0.3874 - mse: 0.3874\n",
            "Epoch 11/15\n",
            "781/781 [==============================] - 2s 2ms/step - loss: 0.3611 - mse: 0.3611\n",
            "Epoch 12/15\n",
            "781/781 [==============================] - 2s 3ms/step - loss: 0.3635 - mse: 0.3635\n",
            "Epoch 13/15\n",
            "781/781 [==============================] - 3s 3ms/step - loss: 0.3483 - mse: 0.3483\n",
            "Epoch 14/15\n",
            "781/781 [==============================] - 2s 2ms/step - loss: 0.3526 - mse: 0.3526\n",
            "Epoch 15/15\n",
            "781/781 [==============================] - 2s 3ms/step - loss: 0.3552 - mse: 0.3552\n",
            "196/196 [==============================] - 1s 4ms/step\n",
            "Mean absolute error =  0.11\n",
            "Mean squared error =  0.39\n",
            "R2 score =  0.91\n"
          ]
        }
      ],
      "source": [
        "\"\"\"PART6: NEURAL NETWORK\"\"\"\n",
        "#import the required dataset\n",
        "import pandas as pd\n",
        "from random import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import sklearn.metrics as sm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#load the dataset\n",
        "df = pd.read_csv('FinalDataset.csv')\n",
        "df['abc'] = df['a'] / (df['b'] * df['c'])\n",
        "X = df.iloc[:, [0, 1, 2, 4]].values\n",
        "#X = df.iloc[:, 0:3].values\n",
        "y = df['res'].values\n",
        "\n",
        "#Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=100\n",
        ")\n",
        "\n",
        "#make the neural network model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(10, activation='relu', input_shape=(X_train.shape[1], )))\n",
        "model.add(layers.Dense(50, activation='relu'))\n",
        "model.add(layers.Dense(200, activation='relu'))\n",
        "model.add(layers.Dense(50, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1))\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mse'])\n",
        "model.summary()\n",
        "\n",
        "#train the model\n",
        "model.fit(X_train, y_train, epochs=15)\n",
        "\n",
        "#predict the test dataset\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "#Calculate the MSE, MAE, R2-SCORE\n",
        "print(\"Mean absolute error = \", round(sm.mean_absolute_error(y_test, y_test_pred), 2))\n",
        "print(\"Mean squared error = \", round(sm.mean_squared_error(y_test, y_test_pred), 2))\n",
        "print(\"R2 score = \", round(sm.r2_score(y_test, y_test_pred), 2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MjkN0DIKimQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "723be5481ed0e85912221e57dcd578d8762ee56f8237b738312dcec1487020e8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}